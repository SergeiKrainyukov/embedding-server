# Руководство по работе с Embedding Server

## Введение

Embedding Server - это мощный инструмент для работы с текстовыми эмбеддингами и семантическим поиском. Сервер использует модель nomic-embed-text через Ollama для создания векторных представлений текста.

## Основные возможности

### Работа с эмбеддингами

Сервер позволяет создавать эмбеддинги для произвольных текстов. Каждый текст автоматически разбивается на чанки оптимального размера (100-256 токенов) с перекрытием в 25 токенов для сохранения контекста.

### Семантический поиск

Используя созданные эмбеддинги, можно выполнять семантический поиск по сохраненным текстам. Поиск основан на косинусном сходстве между векторами.

### RAG (Retrieval-Augmented Generation)

Сервер поддерживает технологию RAG, которая позволяет генерировать ответы на вопросы, используя контекст из базы знаний. Это особенно полезно для создания чат-ботов и систем вопросов-ответов.

## Работа с документами

### Загрузка MD-файлов

Сервер поддерживает загрузку документов в формате Markdown. При загрузке документ автоматически разбивается на чанки, каждый чанк векторизуется и сохраняется в базе данных вместе с метаданными о позиции в документе.

### Поиск по документам

После загрузки документов вы можете задавать вопросы, и сервер будет искать релевантные фрагменты в загруженных документах, используя векторный поиск.

## Архитектура

Сервер построен на Kotlin и использует фреймворк Ktor для обработки HTTP-запросов. Для хранения данных используется встроенная база данных H2.

## Конфигурация

Основные параметры конфигурации:
- Размер чанка: 100-256 токенов
- Перекрытие: 25 токенов
- Нормализация: L2 к диапазону [-1, 1]
- Модель: nomic-embed-text

## Примеры использования

### Загрузка документа

Вы можете загрузить любой MD-файл через API эндпоинт `/api/documents/upload`.

### Поиск информации

Используйте эндпоинт `/api/documents/ask` для поиска информации в загруженных документах с помощью естественного языка.
